<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Anurag Ghosh</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Anurag Ghosh" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="https://anuragghosh.com/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Anurag Ghosh
              </h1>
              <p> 
                I'm a Research Fellow at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-india/">Microsoft Research</a>. I'm part of the Systems Lab, and I work at the intersection of Computer Vision and Systems for driver safety, with <a href="https://www.microsoft.com/en-us/research/people/padmanab/">Venkat Padmanabhan</a> and <a href="https://www.microsoft.com/en-us/research/people/akshayn/">Akshay Nambi</a>.
              </p>
              <p>
                I previously obtained my Bachelors and Masters in Computer Science from <a href="https://www.iiit.ac.in/">IIIT Hyderabad</a>. I was part of <a href="https://cvit.iiit.aa.in">Centre for Visual Information Technology</a>, where I was advised by <a href="https://faculty.iiit.ac.in/~jawahar/">C. V. Jawahar</a> as I worked on problems involving computer vision and sports.
              </p>

              <p style="text-align:center">
                <a target="_blank" href="t-angh@microsoft.com"> Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/anuragxel">GitHub</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=zd0-SNQAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/anuragxel/"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="tn/images/profile.jpg">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I'm interested in computer vision, machine learning, robotics and systems problems in these domains.
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/hams-demo.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Smartphone-based Driver License Testing</h3>
              <br>
              <strong>Anurag Ghosh</strong>, Vijay Lingam, Ishit Mehta, Akshay Nambi, Venkat Padmanabhan, Satish Sangameswaran

              <br>
              <em>ACM Conference on Embedded Networked Sensor Systems (SenSys Demo)</em>, 2019
              <br>
              
              
              
              
              
              <p></p>
              <p><strong>Featured on <a href="https://techcrunch.com/2019/10/31/driving-test-india-microsoft-hams/">TechCrunch</a> and <a href="https://gizmodo.com/microsoft-made-a-smartphone-app-that-can-administer-dri-1839467075">Gizmodo</a></strong>. We demonstrate a low-cost, smartphone-based system for automating key aspects of the driver license test. We have a pilot deployment of our system at an official testing track in India. We will present an analysis of license test results obtained from this pilot, comparing the smartphone-based testing results with manual evaluation.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/hams-alt.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>ALT: Towards Automating Driver License Testing using Smartphones</h3>
              <br>
              Akshay Nambi, Ishit Mehta, <strong>Anurag Ghosh</strong>, Vijay Lingam, Venkat Padmanabhan

              <br>
              <em>ACM Conference on Embedded Networked Sensor Systems (SenSys)</em>, 2019
              <br>
              
              
              
              
              
              <p></p>
              <p>Can a smartphone administer a driver license test? We present ALT, a low-cost smartphone-based system for automating key aspects of the driver license test. A windshield-mounted smartphone serves as the sole sensing platform, with the front camera being used to monitor driver’s gaze, and the rear camera, together with inertial sensors, being used to evaluate driving maneuvers such as parallel parking. The main contributions of this paper are: (a) robust detection of driver’s gaze by combining head pose and eye gaze information, and performing auto-calibration to accommodate environmental variation, (b) a hybrid visual SLAM technique that combines visual features and a sparse set of planar markers, placed optimally in the environment, to derive accurate trajectory information, and (c) an efficient realization on smartphones using both CPU and GPU resources.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/hams-alt.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Analyzing Racket Sports From Broadcast Videos</h3>
              <br>
              Anurag Ghosh

              <br>
              <em>IIIT Hyderabad (Master's Thesis)</em>, 2019
              <br>
              
              
              
              
              
              <p></p>
              <p>Sports video data is recorded for nearly every major tournament but remains archived and inaccessible to large scale data mining and analytics. Many applications depend on specialized camera setups and wearable devices which are costly and unwieldy for players and coaches, specially in a resource constrained environments like India. Firstly, we demonstrate a score based indexing approach for broadcast video data. We build an index to retrieve and view the relevant video segments by automatically tagging segmented rallies with human accessible tags.  Secondly, we propose an end-to-end framework for automatic attributes tagging and analysis of broadcast sport videos. We use commonly available broadcast videos of badminton matches and, unlike previous approaches, we do not rely on special camera setups or additional sensors. We propose a method to analyze a large corpus of broadcast videos by segmenting the points played, tracking and recognizing the players in each point and annotating their respective strokes. Lastly, we adapt our proposed framework for tennis games to mine spatiotemporal and event data from large set of broadcast videos. We demonstrate that we can infer the playing styles between Roger Federer, Rafael Nadal and Novac Djokovic from their Grand Slam matches. We compare and validate our inferences with expert opinions, along with quantatative comparisons with crowdsourced data.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/signals-www19.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Signals Matter: Understanding Popularity and Impact on Stack Overflow</h3>
              <br>
              Arpit Merchant, Daksh Shah, Gurpreet Singh Bhatia, <strong>Anurag Ghosh</strong>, Ponnurangam Kumaraguru

              <br>
              <em>The Web Conference (WWW)</em>, 2019
              <br>
              
              
              
              
              
              <p></p>
              <p>Stack Overflow, a Q&amp;A site on programming, awards reputation points and badges (game elements) to users on performing various actions. Situating our work in Digital Signaling Theory, we investigate the role of these game elements in characterizing social qualities (specifically, popularity and impact) of its users. We operationalize these attributes using common metrics and apply statistical modeling to empirically quantify and validate the strength of these signals.  We present evidence that certain non-trivial badges, reputation scores and age of the user on the site positively correlate with popularity and impact. Further, we find that the presence of costly to earn and hard to observe signals qualitatively differentiates highly impactful users from highly popular users.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/badminton-wacv18.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Towards Structured Analysis of Broadcast Badminton Videos</h3>
              <br>
              <strong>Anurag Ghosh</strong>, Suriya Singh, C.V. Jawahar

              <br>
              <em>IEEE Winter Conference On Applications of Computer Vision (WACV)</em>, 2018
              <br>
              
              
              
              
              
              <p></p>
              <p><strong>Framework piloted by <a href="http://blogs.iiit.ac.in/pbl/">Star Sports for Premier Badminton League</a>.</strong> We propose an end-to-end framework for automatic attributes tagging and analysis of badminton videos. We use commonly available broadcast videos of matches and, unlike previous approaches, does not rely on special camera setups or additional sensors.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/smarttennistv-ncvpripg17.jpg" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>SmartTennisTV: An automatic indexing system for tennis</h3>
              <br>
              <strong>Anurag Ghosh</strong>, C.V. Jawahar

              <br>
              <em>National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics</em>, 2017
              <br>
              
              
              
              
              
              <p></p>
              <p><strong>Best Paper Award Recipient</strong>. We demonstrate a score based indexing approach for tennis videos. Given a broadcast tennis video, we index all the video segments with their scores to create a navigable and searchable match. Our approach temporally segments the rallies in the video and then recognizes the scores from each of the segments, before refining the scores using the knowledge of the tennis scoring system. We also automatically tag the segmented rallies with human accessible tags.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="/tn/images/heritage-eccvw16.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>SmartTennisTV: An automatic indexing system for tennis</h3>
              <br>
              <strong>Anurag Ghosh *</strong>, Yash Patel *, Mohak Sukhwani, C.V. Jawahar

              <br>
              <em>VisArt, Europen Conference on Computer Vision (ECCV)</em>, 2016
              <br>
              
              
              
              
              
              <p></p>
              <p>We present a dynamic story generation approach for the egocentric videos from the heritage sites. Given a short video clip of a ‘heritage-tour’ our method selects a series of short descriptions from the collection of pre-curated text and create a larger narrative. Unlike in the past, these narratives are not merely monotonic static versions from simple retrievals. We propose a method to generate on the fly dynamic narratives of the tour. The series of the text messages selected are optimised over length, relevance, cohesion and information simultaneously. This results in ‘tour guide’ like narratives which are seasoned and adapted to the participants selection of the tour path.</p>

            </td>
          </tr>
          
          
          
        </table>
        <br>
        <br>
        <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

