<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Anurag Ghosh by anuragxel</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/anuragxel">View On GitHub</a></li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Anurag Ghosh</h1>
          <p>Undergrad Researcher in Computer Vision</p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/anuragxel">anuragxel</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h1>
<a id="update-on-visual-localization" class="anchor" href="#update-on-visual-localization" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Update on Visual Localization</h1>

<p>We extracted video frames with associated GPS coordinates. As we had 1 gps coordinate per second and the video was recorded at 30 frames per second. We extracted 2 frames each second from our training videos and assigned them the same GPS coordinates as we know that there wouldn't be much change in GPS value in a second. This resulted in a training set of 5982 images and associated GPS coordinates. For our test set, we similarly extracted 1 frame per second from the test set which do not overlap with our training set (different set of videos) to get 915 frames to test on.</p>

<p>We then  trained a BagOfVisualWords model with a vocabulory size of 500,000 and extracted SIFT features from the images. Our idea of localization involved retrieving the closest training samples for each of the test samples.</p>

<h3>
<a id="random-sample" class="anchor" href="#random-sample" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Random Sample</h3>

<p><img src="https://raw.githubusercontent.com/anuragxel/anuragxel.github.io/master/ReportImages/VL_report_data.png" alt="Random Sample"></p>

<h3>
<a id="result-of-the-random-sample" class="anchor" href="#result-of-the-random-sample" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Result of the random sample</h3>

<p><img src="https://raw.githubusercontent.com/anuragxel/anuragxel.github.io/master/ReportImages/VL_report_data_result.png" alt="Random Sample Result"></p>

<p>The difference in the estimate and the actual coordinates was calculated using Harversine formula which is a widely used formula. Two measures were calculated for different values of 'k', first the mean error distance (mean) (in metres) and other is hit rate of samples (ht10, ht15) above a certain threshold distance (in metres). The values are tabulated below -</p>

<table>
<thead>
<tr>
<th>Measure</th>
<th>NN</th>
<th>US_2</th>
<th>US_3</th>
<th>US_5</th>
</tr>
</thead>
<tbody>
<tr>
<td>loc_5</td>
<td>48.1400</td>
<td>48.2495</td>
<td>49.1247</td>
<td>46.8271</td>
</tr>
<tr>
<td>loc_10</td>
<td>80.3063</td>
<td>81.9475</td>
<td>82.7133</td>
<td>83.1510</td>
</tr>
<tr>
<td>loc_15</td>
<td>90.4814</td>
<td>92.1225</td>
<td>93.3260</td>
<td>95.9519</td>
</tr>
</tbody>
</table>

<h1>
<a id="update-on-dataset" class="anchor" href="#update-on-dataset" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Update on Dataset</h1>

<p>The recorded egocentric videos are of good quality but the associated GPS quality is very bad in indoor areas. So, it was necessary to clip out parts of the video so that experiments can be performed on the embedded video.</p>

<p><img src="https://raw.githubusercontent.com/anuragxel/anuragxel.github.io/master/ReportImages/GPS_Data_Error.png" alt="Error in Indoor Areas"></p>

<p><img src="https://raw.githubusercontent.com/anuragxel/anuragxel.github.io/master/ReportImages/GPS_Data_cleaned.png" alt="Cleaned up data"></p>

<p>Also, a ground truth was established for edges.</p>

<p><img src="https://raw.githubusercontent.com/anuragxel/anuragxel.github.io/master/ReportImages/Graph_edges.png" alt="Edges of the graph"></p>

<p>Textual data has been collected, categorized (into glue and content sentences) and cleaned up accordingly. Me and Yash are currently working on implementing the Bag of Visual Words for visual localization and integrating that to the pipeline, we will be finishing that and running benchmarks <strong>by this weekend</strong>.Also, we will be looking to smooth the gps noise using a <strong>Kalman filter</strong>(<a href="http://www.mdpi.com/1424-8220/13/11/15307/pdf">http://www.mdpi.com/1424-8220/13/11/15307/pdf</a>) and decide whether such an approach is a good idea or not.</p>

<h3>
<a id="hello" class="anchor" href="#hello" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hello!</h3>

<p>This is the page where I'll post updates on my research work.</p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
