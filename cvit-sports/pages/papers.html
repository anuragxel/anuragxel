<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sports Analytics Project</title>

    <!-- Bootstrap Core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- MetisMenu CSS -->
    <link href="../vendor/metisMenu/metisMenu.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="../dist/css/sb-admin-2.css" rel="stylesheet">

    <!-- Morris Charts CSS -->
    <link href="../vendor/morrisjs/morris.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="../vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <div id="wrapper">

        <!-- Navigation -->
        <nav class="navbar navbar-default navbar-static-top" role="navigation" style="margin-bottom: 0">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="index.html">Sports Analytics</a>
            </div>
            <!-- /.navbar-header -->

            <div class="navbar-default sidebar" role="navigation">
                <div class="sidebar-nav navbar-collapse">
                    <ul class="nav" id="side-menu">

                        <li>
                            <a href="index.html"><i class="fa fa-dashboard fa-fw"></i> Timeline</a>
                        </li>
                        <li>
                            <a href="dataset.html"><i class="fa fa-table fa-fw"></i> Dataset</a>
                        </li>
                        <li>
                            <a href="papers.html"><i class="fa fa-bar-chart-o fa-fw"></i> Relevant Papers</a>
                        </li>
                        <li>
                            <a href="ideas.html"><i class="fa fa-edit fa-fw"></i> Ideas</a>
                        </li>
                        <li>
                            <a href="smart_tennis_tv.html"><i class="fa fa-edit fa-fw"></i> Smart Tennis TV</a>
                        </li>
                        <li>
                            <a href="player_stats.html"><i class="fa fa-edit fa-fw"></i> Player Analysis</a>
                        </li>
                        <li>
                            <a href="issues.html"><i class="fa fa-list-alt fa-fw"></i> Issues</a>
                        </li>
                    </ul>
                </div>
                <!-- /.sidebar-collapse -->
            </div>
            <!-- /.navbar-static-side -->
        </nav>

        <div id="page-wrapper">
            <div class="row">
                <div class="col-lg-12">
                    <h1 class="page-header">Relevant Papers</h1>
                </div>
                <!-- /.col-lg-12 -->
            </div>

            <!-- /.row -->
            <div class="row">

                <!-- COLUMN 1 -->
                <div class="col-lg-6">

                  <div class="well">
                      <h2><a href="http://www.sciencedirect.com/science/article/pii/S0262885614001309">Automatic annotation of tennis games: An integration of audio, vision, and learning
</a></h2>
                      <p class="text-danger">Image and Vision Computing, November'14</p>
                      <p>The authors improve upon our previously proposed state-of-the-art tennis ball tracking algorithm.</p>
                      <p>Employ audio signal processing techniques to detect key events and construct features for classifying the events</p>
                      <p>Model event classification (serve, hit, bounce, net, and null) as a sequence labelling problem</p>
                      <p class="text-success">Similar: <a href="http://www.sciencedirect.com/science/article/pii/S1877050915021717">Object Detection and Tracking Based on Trajectory in Broadcast Tennis Video</a></p>
                      <img src="../images/ivc-14-tennis.jpg" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151211035022/Sweet-Spot-Using-Spatiotemporal-Data-to-Discover-and-Predict-Shots-in-Tennis-Paper.pdf">“Sweet-Spot”: Using Spatiotemporal Data to Discover and Predict Shots in Tennis</a></h2>
                      <p class="text-danger">MITSSC'13</p>
                      <p> 1. Find the factors such as location and speed of the incoming  shot  which  are most conducive to a player hitting a  winner
                          (i.e.  “sweet-spot”) or  cause  an error.<br/>
                          2. Do  “live  in-point”  prediction  -  based  on the  shots being  played  during  a rally  we  estimate the probability of  the outcome of  the next shot.<br/></p>
                      <img src="../images/mitssac-13-sweet.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://ieeexplore.ieee.org/document/6836037/">Understanding and Analyzing a Large Collection of Archived Swimming Videos</a></h2>
                      <p class="text-danger">WACV'14, Best Paper</p>
                      <img src="../images/wacv-14-swim.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://www.sciencedirect.com/science/article/pii/S1077314217300012">A technology platform for automatic high-level tennis game analysis</a></h2>
                      <p class="text-danger">CVIU, January'17</p>
                      <p>Automatic system for actions annotation in tennis video sequences for coaching needs. 3D ball trajectory reconstruction and player position detection.  Strokes, serves, and bounces recognition from ball trajectory changes.</p>
                      <p>Also provides hardware architecture, processing modules to perform such analytics.</p>
                      <p class="text-success">Good Reference Hunt!</p>
                      <img src="../images/tech-tennis-17.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://ieeexplore.ieee.org/document/6636679/">An automatic system for sports analytics in multi-camera tennis videos </a></h2>
                      <p class="text-danger">ICAVSBS'13</p>
                      <p>Adapted a mono-camera detection and tracking system, originally designed for video surveillance to do sport analytics.</p>
                      <p>Extracts player trajecteries by computing homographies wrt to multiple cameras. Shows some simple statistics over it.</p>
                      <img src="../images/auto-sports-analytics-13.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://link.springer.com/article/10.1007/s11063-012-9267-4">Active Foreground Region Extraction and Tracking for Sports Video Annotation</a></h2>
                      <p class="text-danger">Neural Processing Letters, February'13</p>
                      <p>They present a semi-parametric method for the automatic segmentation of a sport video and the extraction of its dominant regions, robust to different sport scenarios, without the need of camera calibration or background extraction. </p>
                      <img src="../images/active-region-13.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="https://researchweb.iiit.ac.in/~rahul.anand/">Automated top view registration of broadcast football videos</a></h2>
                      <p class="text-danger">CVPR'17 (Under Review)</p>
                      <p>Proposes an alternate approach exploiting the edge information and demonstrates its success in a specific scenario of registering football broadcast video frames on the static top view model of the playing surface.</p>
                  </div>

                  <div class="well">
                      <h2><a href="http://link.springer.com/chapter/10.1007/978-3-540-74260-9_100">Automated Stroke Classification in Tennis</a></h2>
                      <p class="text-danger">International Conference on Image Analysis and Recognition (ICIAR) '07</p>
                      <p>Classifying the different tennis strokes (Forehand, Backhand and No Shot) is the prime goal of this project.</p>
                      <p>Algorithm uses the gradient information of the player's skeleton. The player is modeled using color histogram and tracked across the video using histogram back projection. An oriented histogram of the skeleton obtained in each frame forms the feature vector which is then sent to a SVM classifier.</p>
                      <img src="../images/stroke-class-07.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://www.sciencedirect.com/science/article/pii/S1077314208001355">A framework for flexible summarization of racquet sports video using multiple modalities</a></h2>
                      <p class="text-danger">CVIU, March'09</p>
                      <p>Our approach combines the structure event detection method with the highlight ranking algorithm</p>
                      <p>Firstly, unsupervised shot clustering and supervised audio classification are performed to obtain the visual and audio mid-level patterns respectively.
                         Then, a temporal voting scheme for structure event detection is proposed by utilizing the correspondence between audio and video content.
                         Finally, by using the affective features extracted from the detected events, a linear highlight model is adopted to rank the detected events in terms of their exciting degrees.</p>
                      <p>Human evaluation for highlights.</p>
                      <img src="../images/summarize-racquet-multimodal-09.png" class="img-responsive center-block"></img>
                  </div>
                    <!-- /.panel -->
                </div>

                <!-- COLUMN 2 -->
                <!-- /.col-lg-8 -->
                <div class="col-lg-6">

                  <div class="well">
                      <h2><a href="http://www.sloansportsconference.com/wp-content/uploads/2016/02/1475-Other-Sport.pdf">"The Thin Edge of the Wedge”: Accurately Predicting Shot Outcomes in Tennis using Style and Context Priors</a></h2>
                      <p class="text-danger">MITSSAC'16, Best Paper</p>
                      <p>The authors show that a small set of features can be used to predict shot outcomes.</p>
                      <p>Using style priors, i.e. cluster players and forming player descriptors significantly improves performance</p>
                      <p>The handcrafted features are extracted from Hawk-eye data.</p>
                      <img src="../images/mitssac-16-shot.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="http://lib.ugent.be/fulltxt/RUG01/002/153/740/RUG01-002153740_2014_0001_AC.pdf">Badminton game analysis from video sequences</a></h2>
                      <p class="text-danger">Master's Dissertation</p>
                      <p>Used Computer vision techniques to collect statistics during badminton matches.  The end result is a chronological list with statistics of every
                         stroke played in a certain rally.  Those statistics include the start and end zone of the stroke and the stroke type.</p>
                      <p class="text-success">Similar: <a href="http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6575/pdf/imm6575.pdf">Badminton shot classification in compressed video with baseline angled camera</a></p>
                      <img src="../images/badminton-13-masters.png" class="img-responsive center-block"></img>
                  </div>

                  <div class="well">
                      <h2><a href="https://www.disneyresearch.com/project/spatiotemporal-data/">Assessing Team Strategy using Spatiotemporal Data</a></h2>
                      <p class="text-danger">ACM SIGKDD'13</p>
                      <p>Uses an entire football season of ball tracking data to reinforce the common held belief that
                        teams should aim to “win home games and draw away ones”. </p>
                      <p>1. A representation of team behavior is formed by chunking spatiotemporal signal into a series of quantized bins.<br/>
                         2. Generated an expectation model of team behavior based on a code-book of past performance.<br/>
                      </p>
                      <img src="../images/Assessing-Team-Strategy-Using-Spatiotemporal-Data-Image-1024x653.png" class="img-responsive center-block"></img>
                  </div>

                 <div class="well">
                      <h2><a href="http://www.sciencedirect.com/science/article/pii/S0957417409001146">An intelligent strategy for the automatic detection of highlights in tennis video recordings</a></h2>
                      <p class="text-danger">Expert Systems with Applications'09</p>
                      <p>Proposes the use of computational intelligence strategies and information from both the audio and video domains to automatically locate sporting highlight on personal video playback devices. </p>
                      <img src="../images/highlight-09-detection.png" class="img-responsive center-block"></img>

                </div>

                <div class="well">
                     <h2><a href="http://link.springer.com/article/10.1007/s11042-013-1558-x">Accurate ball trajectory tracking and 3D visualization for computer-assisted sports broadcast</a></h2>
                     <p class="text-danger">Multimedia Tools and Applications, December'14</p>
                     <p>Comparing to other set ups, the main contribution of this work lays on the utilization of an unique camera per border line to extract 3D bounce point information.</p>
                     <img src="../images/accurate-ball-track-14.png" class="img-responsive center-block"></img>

                </div>

                <div class="well">
                     <h2><a href="http://link.springer.com/article/10.1007/s12283-011-0062-7">Impact characteristics of the ball and racket during play at the Wimbledon qualifying tournament</a></h2>
                     <p class="text-danger">Sports Engineering, July'11</p>
                     <p>The method used records racket and ball movement in 3D, intrudes minimally into the player’s environment. The method allows accurate measurement of ball and racket speeds, impact positions, and angular velocities of the racket in three-dimensions.</p>
                     <img src="../images/impact-racket-11.png" class="img-responsive center-block"></img>
                </div>

                <div class="well">
                     <h2><a href="https://www.irisa.fr/metiss/ggravier/biblio/04/coldefy-mmsp-04.pdf">Tennis video abstraction from audio and visual cues</a></h2>
                     <p class="text-danger">Workshop on Multimedia Signal Processing'04</p>
                     <p>Designed an efficient and accurate temporal segmentation of the video into segments homogeneous w.r.t. the camera motion.</p>
                     <p>Focus on the creation of a selective summary containing the best winning serves and rallies of the match, using "applause" and "ball hit" clusters.</p>
                     <img src="../images/tennis-abstraction-04.png" class="img-responsive center-block"></img>
                </div>

                <div class="well">
                     <h2><a href="http://epubs.surrey.ac.uk/733266/2/BMVC07.pdf">All Pairs Shortest Path Formulation for Multiple Object Tracking with Application to Tennis Video Analysis</a></h2>
                     <p class="text-danger">BMVC'07</p>
                     <p>We extend our previous work to track multiple tennis balls fully automatically. The algorithm presented in this paper requires the set of all-pairs shortest paths in a directed and edge-weighted graph.</p>
                     <p>We also propose an efficient All-Pairs Shortest Path algorithm by exploiting a special topological property of the graph.</p>
                     <p class="text-success"> Prev: <a href="http://epubs.surrey.ac.uk/733265/1/BMVC05.pdf">A Tennis Ball Tracking Algorithm for Automatic Annotation of Tennis Match, BMVC'05</a>
                     <p class="text-success"> Prev: <a href="http://www3.ee.surrey.ac.uk/CVSSP/Publications/papers/yan-cvpr-2006.pdf">A Novel Data Association Algorithm for Object Tracking in Clutter with Application to Tennis Video Analysis</a>
                     <img src="../images/apsp-multi-object-07.png" class="img-responsive center-block"></img>
                </div>

                <div class="well">
                     <h2><a href="http://ieeexplore.ieee.org/document/1246883/">Generic approach to highlights extraction from a sport video</a></h2>
                     <p class="text-danger">ICIP'03</p>
                     <p>Instead, we search for highlights at places where strong excitement is evoked in the user by the content of a video. It is namely realistic to assume that independent
                       of the type of a highlighting event, each such event induces an increase in user's excitement. We mimic the changes in user's excitement by observing the temporal
                       behavior of domain-independent audiovisual signal properties and the editing scheme of a video.</p>
                     <img src="../images/highlight-icip-03.png" class="img-responsive center-block"></img>
                </div>
                    <!-- /.panel .chat-panel -->
                </div>
                <!-- /.col-lg-4 -->
            </div>
            <!-- /.row -->
        </div>
        <!-- /#page-wrapper -->

    </div>
    <!-- /#wrapper -->

    <!-- jQuery -->
    <script src="../vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="../vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Metis Menu Plugin JavaScript -->
    <script src="../vendor/metisMenu/metisMenu.min.js"></script>

    <!-- Morris Charts JavaScript -->
    <script src="../vendor/raphael/raphael.min.js"></script>
    <script src="../vendor/morrisjs/morris.min.js"></script>
    <script src="../data/morris-data.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="../dist/js/sb-admin-2.js"></script>

</body>

</html>
